<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>OpenAI Audio Transcription</title>
    <script type="importmap">
      {
        "imports": {
          "preact-stand-alone": "https://cdn.jsdelivr.net/npm/preact-htm-signals-standalone/dist/standalone.js"
        }
      }
    </script>
    <style>
      body {
        font-family: system-ui;
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
      }
      textarea {
        width: 100%;
        height: 100px;
        margin: 10px 0;
      }
      button {
        padding: 10px 20px;
        background: #007bff;
        color: white;
        border: none;
        cursor: pointer;
        margin-right: 10px;
      }
      button:hover {
        background: #0056b3;
      }
      button:disabled {
        background: #cccccc;
        cursor: not-allowed;
      }
      .error {
        color: red;
        margin-top: 10px;
      }
      .controls {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 1rem;
        margin-bottom: 1rem;
        padding: 1rem;
        background: #f5f5f5;
        border-radius: 8px;
      }
      .control-group {
        display: flex;
        flex-direction: column;
        gap: 0.5rem;
      }
      .control-group label {
        font-weight: 500;
      }
      select {
        padding: 0.5rem;
        border: 1px solid #ddd;
        border-radius: 4px;
        background: white;
      }
      .recording-status {
        display: flex;
        align-items: center;
        gap: 1rem;
        margin: 1rem 0;
      }
      .recording-indicator {
        width: 12px;
        height: 12px;
        border-radius: 50%;
        background: #ccc;
      }
      .recording-indicator.active {
        background: #ff4444;
        animation: pulse 1s infinite;
      }
      @keyframes pulse {
        0% {
          opacity: 1;
        }
        50% {
          opacity: 0.5;
        }
        100% {
          opacity: 1;
        }
      }
      .transcript {
        margin-top: 20px;
        padding: 1rem;
        background: #f8f9fa;
        border-radius: 4px;
        white-space: pre-wrap;
      }
    </style>
  </head>
  <body>
    <script>
      const apiKey = localStorage.getItem('openaiApiKey') || ''

      if (!apiKey) {
        const key = prompt('Please enter your Open AI API key:')
        if (key) saveApiKey(key)
      }

      function saveApiKey(key) {
        localStorage.setItem('openaiApiKey', key)
        apiKey.value = key
      }
    </script>

    <script type="module">
      import { html, render, signal } from 'preact-stand-alone'

      const apiKey = signal(localStorage.getItem('openaiApiKey') || '')
      const language = signal('en')
      const isRecording = signal(false)
      const transcript = signal('')
      const error = signal('')
      const isLoading = signal(false)

      let mediaRecorder = null
      let audioChunks = []

      async function startRecording() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          })
          mediaRecorder = new MediaRecorder(stream)
          audioChunks = []

          mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data)
          }

          mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, {
              type: 'audio/webm',
            })
            await transcribeAudio(audioBlob)
          }

          mediaRecorder.start()
          isRecording.value = true
          error.value = ''
        } catch (err) {
          error.value = `Error accessing microphone: ${err.message}`
        }
      }

      function stopRecording() {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
          mediaRecorder.stop()
          mediaRecorder.stream.getTracks().forEach((track) =>
            track.stop()
          )
          isRecording.value = false
        }
      }

      async function transcribeAudio(audioBlob) {
        isLoading.value = true
        error.value = ''

        const formData = new FormData()
        formData.append('file', audioBlob, 'recording.webm')
        formData.append('model', 'whisper-1')
        if (language.value) {
          formData.append('language', language.value)
        }

        try {
          const response = await fetch(
            'https://api.openai.com/v1/audio/transcriptions',
            {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${apiKey.value}`,
              },
              body: formData,
            },
          )

          if (!response.ok) {
            const errorData = await response.json()
            throw new Error(
              errorData.error?.message ||
                `HTTP error! status: ${response.status}`,
            )
          }

          const data = await response.json()
          transcript.value = data.text
        } catch (err) {
          error.value = `Error: ${err.message}`
        } finally {
          isLoading.value = false
        }
      }

      const languages = {
        en: 'English',
        es: 'Spanish',
        fr: 'French',
        de: 'German',
        it: 'Italian',
        pt: 'Portuguese',
        nl: 'Dutch',
        ja: 'Japanese',
        ko: 'Korean',
        zh: 'Chinese',
        ru: 'Russian',
        ar: 'Arabic',
        hi: 'Hindi',
        tr: 'Turkish',
      }

      function App() {
        return html`
          <div>
            <h1>Audio Transcription with OpenAI</h1>
            
            <div class="controls">
              <div class="control-group">
                <label for="language">Language (Optional)</label>
                <select 
                  id="language" 
                  value=${language.value} 
                  onChange=${(e) => (language.value = e.target.value)}
                >
                  <option value="">Auto-detect</option>
                  ${
          Object.entries(languages).map(([code, name]) =>
            html`<option value=${code}>${name}</option>`
          )
        }
                </select>
              </div>
            </div>

            <div class="recording-status">
              <div class="recording-indicator ${
          isRecording.value ? 'active' : ''
        }"></div>
              <span>${
          isRecording.value ? 'Recording...' : 'Not recording'
        }</span>
            </div>

            <button 
              onClick=${
          isRecording.value ? stopRecording : startRecording
        }
              disabled=${isLoading.value}
            >
              ${
          isRecording.value ? 'Stop Recording' : 'Start Recording'
        }
            </button>

            ${
          error.value && html`<div class="error">${error.value}</div>`
        }
            ${isLoading.value && html`<div>Transcribing audio...</div>`}
            ${
          transcript.value && html`
              <div class="transcript">
                <h3>Transcript:</h3>
                ${transcript.value}
              </div>
            `
        }
          </div>
        `
      }

      render(html`<${App} />`, document.body)
    </script>
  </body>
</html>
